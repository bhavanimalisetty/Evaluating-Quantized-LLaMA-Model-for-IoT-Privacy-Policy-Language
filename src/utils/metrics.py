import statistics
from typing import List
from evaluate import load
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import pandas as pd
import torch
from collections import Counter
import numpy as np
from gensim.models import KeyedVectors
from nltk.tokenize import word_tokenize
import nltk
from gensim.scripts.glove2word2vec import glove2word2vec
from utilslib import generate_box_plot, preprocess_text
import matplotlib.pyplot as plt

class RougeMetric:
    def __init__(self) -> None:
        """ Instantiate RougeMetric with Rouge model.
        
        Params:
            None

        Returns:
            None
        """
        self.rouge = load("rouge")
        self.rougeScore = \
        {
            "rouge1":
                        {
                            "data":[], "statistics": {"mean": 0, "median": 0, "mode": 0, "stdev":0}
                        },
            "rouge2":
                        {
                            "data":[], "statistics": {"mean": 0, "median": 0, "mode": 0, "stdev":0}
                        },
            "rougeL":
                        {
                            "data":[], "statistics": {"mean": 0, "median": 0, "mode": 0, "stdev":0}
                        },
            "rougeLsum":
                        {
                            "data":[], "statistics": {"mean": 0, "median": 0, "mode": 0, "stdev":0}
                        }
        }
        self.ROUGE_TYPES = ["rouge1", "rouge2", "rougeL", "rougeLsum"]
        print("Rouge Metric loaded successfully.")
              
    def getRougeMetric(self, df: pd.DataFrame) -> None:
        """ This function is used to generate rouge value for each data point and generate stats for each rouge type.
        
        Params:
            df: DataFrame generated by MyModel model as a result containing Generated Text and Reference Text for each datapoint. 

        Returns:
            None
        """
        for index,row in df.iterrows():
            computedRouge = self.rouge.compute(predictions=[row['Generated Text']], references=[row['Reference Text']])
            print("Computed Rouge: ",computedRouge)
            print("\n\n")

            for rougeType in self.ROUGE_TYPES:
                self.rougeScore[rougeType]["data"].append(computedRouge[rougeType])
        
        for rougeType in self.ROUGE_TYPES:
            v=self.rougeScore[rougeType]
            v["statistics"]["mean"] = statistics.mean(v["data"])
            v["statistics"]["median"] = statistics.median(v["data"])
            v["statistics"]["mode"] = statistics.mode(v["data"])
            v["statistics"]["stdev"] = statistics.stdev(v["data"])
        
        print("***ROUGE SCORE***\n")
        for rougeType in self.ROUGE_TYPES:
            v=self.rougeScore[rougeType]
            print(rougeType,v["statistics"])
            generate_box_plot(v["data"], xlabel =  rougeType + " Scale", ylabel = rougeType + " values", box_color = "lightblue")

class BertMetric:
    def __init__(self) -> None:
        """ Instantiate BertMetric with Bert model.
        
        Params:
            None

        Returns:
            None
        """
        self.bert = load("bertscore")
        self.bertScore = \
        {
            "precision":{"data":[], "statistics": {"mean": 0, "median": 0, "mode": 0, "stdev":0}}, 
            "recall":{"data":[], "statistics": {"mean": 0, "median": 0, "mode": 0, "stdev":0}}, 
            "f1_score":{"data":[], "statistics": {"mean": 0, "median": 0, "mode": 0, "stdev":0}}
        }

    def getBertMetric(self, df: pd.DataFrame) -> None:
        """ This function is used to compute Bert Score for each data point and generate the statistics for precision, recall and F1-Score. 
        
        Params:
            df: DataFrame generated by MyModel model as a result containing Generated Text and Reference Text for each datapoint. 

        Returns:
            None
        """
        for index, row in df.iterrows():
            computedBert=self.bert.compute(predictions=[row['Generated Text']], references=[row['Reference Text']],lang="en")
            print("Computed Bert: ",computedBert)
            print("\n\n")
            self.bertScore["precision"]["data"].append(computedBert["precision"][0])
            self.bertScore["recall"]["data"].append(computedBert["recall"][0])
            self.bertScore["f1_score"]["data"].append(computedBert["f1"][0])
        
        for k,v in self.bertScore.items():
            v["statistics"]["mean"] = statistics.mean(v["data"])
            v["statistics"]["median"] = statistics.median(v["data"])
            v["statistics"]["mode"] = statistics.mode(v["data"])
            v["statistics"]["stdev"] = statistics.stdev(v["data"])
        
        print("***BERT SCORE***\n")
        print(self.bertScore)
        for k,v in self.bertScore.items():
            generate_box_plot(v["data"], xlabel = "Bert " + k + " Scale", ylabel = "Bert " + k + " values", box_color = "lightpink")            

class RobertaMetric:
    def __init__(self) -> None:
        """ Instantiate RobertaMetric with Roberta Large V1 model.
        
        Params:
            None

        Returns:
            None
        """
        self.model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')
        self.robertaStatistics = {"mean": 0, "median": 0, "mode": 0, "stdev": 0}
        print("Roberta Model loaded successfully.")

    def __calculate_similarity(self, row: pd.Series) -> float:
        """ This function is used to compute cosine similarity for each row of a DataFrame containing generated and reference text.
        
        Params:
            row: A row of a dataframe containing generated and reference text.

        Returns:
            Float: A floating value indicating cosine similarity.
        """
        embeddings = self.model.encode([row['Reference Text'], row['Generated Text']])
        similarity_matrix = cosine_similarity([embeddings[0]], [embeddings[1]])
        return similarity_matrix[0][0]
    
    def getRobertaMetrics(self, df: pd.DataFrame) -> None:
        """ This function is used to generate stats for Roberta Model using cosine similarity.
        
        Params:
            df: DataFrame generated by MyModel model as a result containing Generated Text and Reference Text for each datapoint.

        Returns:
            None
        """
        df['Cosine Similarity'] = df.apply(lambda row: self.__calculate_similarity(row), axis=1)
        print(df[['Reference Text', 'Generated Text', 'Cosine Similarity']])
        self.robertaStatistics["mean"] = statistics.mean(df['Cosine Similarity'])
        self.robertaStatistics["median"] = statistics.median(df['Cosine Similarity'])
        self.robertaStatistics["mode"] = statistics.mode(df['Cosine Similarity'])
        self.robertaStatistics["stdev"] = statistics.stdev(df['Cosine Similarity'])

        print("*** ROBERTA METRIC ***\n")
        print(self.robertaStatistics)
        generate_box_plot(df['Cosine Similarity'], xlabel = "Roberta Scale", ylabel = "Roberta values", box_color = "lightgreen")

class PyTorchMetric:
    def __init__(self) -> None:
        """ Instantiate PyTorchMetric.
        
        Params:
            None

        Returns:
            None
        """
        nltk.download('punkt')
        self.pyTorchStatistics = {"mean": 0, "median": 0, "mode": 0, "stdev": 0}
        print("PyTorch Model loaded successfully.")
    
    # Calculate the cosine similarity between two texts
    def __cosine_similarity_pytorch(self, text1: str, text2: str) -> float:
        """ This function is used to find the cosine similarity between two tensors using both the texts. 
        
        Params:
            text1: A string to compute cosine similarity.
            text2: A string to compute cosine similarity.

        Returns:
            float: Computed cosine similarity between two strings. 
        """
        # Preprocess the texts
        text1 = preprocess_text(text1)
        text2 = preprocess_text(text2)

        # Create word frequency dictionaries
        text1_counter = Counter(text1)
        text2_counter = Counter(text2)

        # Get unique words
        words = list(set(text1 + text2))

        # Create word vectors
        vector1 = [text1_counter[word] for word in words]
        vector2 = [text2_counter[word] for word in words]

        # Convert vectors to tensors
        text1_tensor = torch.tensor(vector1, dtype=torch.float)
        text2_tensor = torch.tensor(vector2, dtype=torch.float)

        # Calculate dot product
        dot_product = torch.dot(text1_tensor, text2_tensor)

        # Calculate norms
        norm1 = torch.norm(text1_tensor)
        norm2 = torch.norm(text2_tensor)

        # Calculate cosine similarity
        cosine_similarity = dot_product / (norm1 * norm2)

        return cosine_similarity.item()
    
    def getPyTorch(self, df: pd.DataFrame) -> None:
        """ This function is used to generate cosine similarities and stats of reference and generated text 
            for each data point using pytorch.
        
        Params:
            df: A DataFrame containing reference and generated text of each datapoint.

        Returns:
            None
        """
        # Calculate cosine similarity for each pair of 'Generated Text' and 'Reference Text'
        print('---PYTORCH---')
        
        similarities = []
        for index, row in df.iterrows():
            similarity = self.__cosine_similarity_pytorch(row['Reference Text'], row['Generated Text'])
            similarities.append(similarity)

        # Add the similarities to the DataFrame
        df['Cosine Similarity'] = similarities

        # Show the DataFrame with the 'Generated Text', 'Reference Text', and 'Cosine Similarity'
        print(df[[ 'Reference Text', 'Generated Text','Cosine Similarity']])
        self.pyTorchStatistics["mean"] = statistics.mean(df['Cosine Similarity'])
        self.pyTorchStatistics["median"] = statistics.median(df['Cosine Similarity'])
        self.pyTorchStatistics["mode"] = statistics.mode(df['Cosine Similarity'])
        self.pyTorchStatistics["stdev"] = statistics.stdev(df['Cosine Similarity'])
        print(self.pyTorchStatistics)
        generate_box_plot(df['Cosine Similarity'], xlabel = "PyTorch Scale", ylabel = "PyTorch values", box_color = "yellow")

class WordEmbeddingsModel:    
    def __init__(self, word2VecModelName) -> None:
        """ Instantiate WordEmbedding for Glove, Word2Vec and FastText models based on model name.
        
        Params:
            word2VecModelName: A string value containing word-embedding model name to instantiate the model.

        Returns:
            None
        """
        self.wordEmbeddingsModelName = word2VecModelName
        nltk.download('punkt')
        self.wordEmbeddingsModel = {"mean": 0, "median": 0, "mode": 0, "stdev": 0}

        if word2VecModelName == "Word2Vec":
            self.file_path="../../../WordEmbeddings/GoogleNews-vectors-negative300.bin"
            self.model = KeyedVectors.load_word2vec_format(self.file_path, binary=True)
        
        elif word2VecModelName == "GLOVE":
            self.file_path = '../../../WordEmbeddings/glove.6B.300d.txt'
            glove_input_file = self.file_path

            # Path to word2vec format output file
            self.file_path = self.file_path + "glove.6B.300d.word2vec.txt"

            # save in word2vec format
            glove2word2vec(glove_input_file,self.file_path)
            self.model = KeyedVectors.load_word2vec_format(self.file_path, binary=False)

        elif word2VecModelName == "FASTTEXT":
            self.file_path = '../../../WordEmbeddings/wiki-news-300d-1M.vec'
            self.model = KeyedVectors.load_word2vec_format(self.file_path, binary=False)

        else:
            raise RuntimeError("Invalid word2vec model name.")
        print("***{}***".format(word2VecModelName))

    def getWordEmbeddings(self, df: pd.DataFrame) -> None:
        """ This function is used to generate cosine similarities and stats of reference and generated text 
            for each data point using word-embeddings.
        
        Params:
            df: A DataFrame containing reference and generated text of each datapoint.

        Returns:
            None
        """
        similarities = []
        for index, row in df.iterrows():
            preprocess_text1 = preprocess_text(row['Generated Text'])
            preprocess_text2 = preprocess_text(row['Reference Text'])

            # Initialize arrays to store word vectors
            vector_1_array = []
            vector_2_array = []

            # Generate arrays to store word vectors
            for word in preprocess_text1:
                try:
                    vector_1_array.append(self.model[word])
                except KeyError:
                    # If the word is not in the vocabulary, you can skip it or use a default value
                    pass

            # Create word vectors for each word in 'Reference Text'
            for word in preprocess_text2:
                try:
                    vector_2_array.append(self.model[word])
                except KeyError:
                    # If the word is not in the vocabulary, you can skip it or use a default value
                    pass
            # Calculate column-wise averages for 'Generated Text' vectors
            vec_1_sums = np.mean(vector_1_array, axis=0)

            # Calculate column-wise averages for 'Reference Text' vectors
            vec_2_sums = np.mean(vector_2_array, axis=0)

            # Calculate cosine similarity
            similarity_matrix = cosine_similarity(vec_1_sums.reshape(1, -1), vec_2_sums.reshape(1, -1))

            # Get the similarity score between the two vectors
            cosine_similarity_score = similarity_matrix[0][0]
            similarities.append(cosine_similarity_score)

        # Add the similarities to the DataFrame
        df['WordEmbeddingSimilarity'] = similarities

        # Show the DataFrame with the 'Generated Text', 'Reference Text', and 'WordEmbeddingSimilarity'
        print(df[['Generated Text', 'Reference Text', 'WordEmbeddingSimilarity']])
        self.wordEmbeddingsModel["mean"] = statistics.mean(df['WordEmbeddingSimilarity'])
        self.wordEmbeddingsModel["median"] = statistics.median(df['WordEmbeddingSimilarity'])
        self.wordEmbeddingsModel["mode"] = statistics.mode(df['WordEmbeddingSimilarity'])
        self.wordEmbeddingsModel["stdev"] = statistics.stdev(df['WordEmbeddingSimilarity'])
        print(self.wordEmbeddingsModel)
        generate_box_plot(df['WordEmbeddingSimilarity'], xlabel = self.wordEmbeddingsModelName + " Scale", ylabel =  self.wordEmbeddingsModelName + " values", box_color = "orange")

class ComparativeRougeLsum:
    def __init__(self):
        """ Initializes the Rouge evaluation metric. """
        self.rouge = load('rouge')

    def extract_rouge_lsum(self, df):
        """ Extracts ROUGE-Lsum scores from a DataFrame containing 'Generated Text' and 'Reference Text'. """
        scores = self.rouge.compute(predictions=df['Generated Text'].tolist(), references=df['Reference Text'].tolist(), rouge_types=["rougeLsum"])
        rouge_lsum_scores = [score['rougeLsum'].mid.fmeasure for score in scores]
        return rouge_lsum_scores

    def generate_boxplot_for_bits(self, bit_data, labels):
        """ Generates a box plot for the different bit configurations.

        Params:
            bit_data (list of list): A list containing ROUGE-Lsum scores for each bit configuration.
            labels (list): A list of labels for each bit configuration.
        """
        plt.figure(figsize=(10, 6))
        plt.boxplot(bit_data, labels=labels, patch_artist=True,
                    boxprops=dict(facecolor='lightblue', color='black'),
                    medianprops=dict(color='black'),
                    whiskerprops=dict(color='black'),
                    capprops=dict(color='black'),
                    flierprops=dict(marker='o', color='black', alpha=0.5))
        plt.title('ROUGE-Lsum Distribution Across Bit Configurations')
        plt.ylabel('ROUGE-Lsum Scores')
        plt.grid(True)
        plt.show()

    def analyze(self, df_4bit, df_5bit, df_8bit):
        """ Analyzes the provided DataFrames and generates a comparative box plot.

        Params:
            df_4bit (DataFrame): DataFrame for 4-bit data.
            df_5bit (DataFrame): DataFrame for 5-bit data.
            df_8bit (DataFrame): DataFrame for 8-bit data.
        """
        rouge_lsum_4bit = self.extract_rouge_lsum(df_4bit)
        rouge_lsum_5bit = self.extract_rouge_lsum(df_5bit)
        rouge_lsum_8bit = self.extract_rouge_lsum(df_8bit)

        self.generate_boxplot_for_bits([rouge_lsum_4bit, rouge_lsum_5bit, rouge_lsum_8bit], ['4-bit', '5-bit', '8-bit'])
class Metrics:
    def getAllMetrics(self, df: pd.DataFrame) -> None:
        """ This function is used to generate mertics for a dataframe containing reference and generated text using 
            Rogue, Bert, Roberta, PyTorch, Word2Vec, Glove and FastText.
        
        Params:
            df: A DataFrame containing reference and generated text of each datapoint.

        Returns:
            None
        """
        rougeMetric = RougeMetric()
        rougeMetric.getRougeMetric(df)
        bertMetric = BertMetric()
        bertMetric.getBertMetric(df)
        robertaMetric = RobertaMetric()
        robertaMetric.getRobertaMetrics(df)
        pyTorchMetric = PyTorchMetric()
        pyTorchMetric.getPyTorch(df)

        WordEmbeddingModels = ["Word2Vec", "GLOVE", "FASTTEXT"]
        for wordEmbeddingModelName in WordEmbeddingModels:
            wordEmbeddingModel = WordEmbeddingsModel(wordEmbeddingModelName)
            wordEmbeddingModel.getWordEmbeddings(df)

class CombinedMetrics:
    def getAllMetrics(self, df_4bit: pd.DataFrame, df_5bit: pd.DataFrame,df_8bit: pd.DataFrame, ) -> None:
        comparativerougeLsum = ComparativeRougeLsum ()
        comparativerougeLsum.analyze(df_4bit, df_5bit, df_8bit) 

