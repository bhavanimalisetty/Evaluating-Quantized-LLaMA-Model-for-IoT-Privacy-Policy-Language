import statistics
from typing import List
from evaluate import load
import pandas as pd
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
import pandas as pd
import torch
from collections import Counter
import numpy as np
from gensim.models import KeyedVectors
from nltk.tokenize import word_tokenize
import nltk
from gensim.scripts.glove2word2vec import glove2word2vec
from utilslib import generate_box_plot, preprocess_text
import matplotlib.pyplot as plt
from matplotlib.ticker import AutoMinorLocator, MultipleLocator, FormatStrFormatter

class RougeMetric:
    def __init__(self) -> None:
        """ Instantiate RougeMetric with Rouge model.
        
        Params:
            None

        Returns:
            None
        """
        self.rouge = load("rouge")
        self.ROUGE_TYPES = ["rouge1", "rouge2", "rougeL", "rougeLsum"]
        self.rouge_scores = {}  # Dictionary to store Rouge scores for each dataframe
        for dataframe_name in ["df_q4", "df_q5", "df_q8"]:
            self.rouge_scores[dataframe_name] = {
                rouge_type: {"data": [], "statistics": {"mean": 0, "median": 0, "mode": 0, "stdev": 0}}
                for rouge_type in self.ROUGE_TYPES
            }
        print("Rouge Metric loaded successfully.")
              
    def getRougeMetric(self, df_q4: pd.DataFrame, df_q5: pd.DataFrame, df_q8: pd.DataFrame) -> None:
        """ This function is used to generate Rouge value for each data point and generate stats for each Rouge type.
        
        Params:
            df_q4: DataFrame generated by MyModel model as a result containing Generated Text and Reference Text for each datapoint by 4-bit Bloke LLM.
            df_q5: DataFrame generated by MyModel model as a result containing Generated Text and Reference Text for each datapoint by 5-bit Bloke LLM.
            df_q8: DataFrame generated by MyModel model as a result containing Generated Text and Reference Text for each datapoint by 8-bit Bloke LLM.

        Returns:
            None
        """
        dataframes = {"df_q4": df_q4, "df_q5": df_q5, "df_q8": df_q8}
        
        for dataframe_name, dataframe in dataframes.items():
            for index, row in dataframe.iterrows():
                computed_rouge = self.rouge.compute(predictions=[row['Generated Text']], references=[row['Reference Text']])
                print("Computed Rouge: ", computed_rouge)
                print("\n\n")

                for rouge_type in self.ROUGE_TYPES:
                    self.rouge_scores[dataframe_name][rouge_type]["data"].append(computed_rouge[rouge_type])

            for rouge_type in self.ROUGE_TYPES:
                v = self.rouge_scores[dataframe_name][rouge_type]
                v["statistics"]["mean"] = statistics.mean(v["data"])
                v["statistics"]["median"] = statistics.median(v["data"])
                v["statistics"]["mode"] = statistics.mode(v["data"])
                v["statistics"]["stdev"] = statistics.stdev(v["data"])
        
            print("***ROUGE SCORE***\n")
            for rouge_type in self.ROUGE_TYPES:
                v = self.rouge_scores[dataframe_name][rouge_type]
                print(rouge_type, v["statistics"])
        print(self.rouge_scores)

        for rouge_type in self.rouge_scores['df_q4']:            
            fig = plt.figure(figsize=(5, 5))
            df_q4_data = self.rouge_scores['df_q4'][rouge_type]['data']
            df_q5_data = self.rouge_scores['df_q5'][rouge_type]['data']
            df_q8_data = self.rouge_scores['df_q8'][rouge_type]['data']
            boxprops = dict(facecolor = "none", edgecolor = 'black')
            medianprops = dict(color='black')
            flierprops = dict(marker = 'o', markerfacecolor = "#F55252", markersize = 8, linestyle = 'none')
           
            # Create box plots
            bplot = plt.boxplot([df_q4_data, df_q5_data, df_q8_data], labels=['4 bit', '5 bit', '8 bit'], patch_artist=True, boxprops=boxprops, medianprops=medianprops, flierprops=flierprops)

            colors = ['skyblue', 'lightgreen', 'yellow']  # Colors for 4 bit, 5 bit, 8 bit
            for patch, color in zip(bplot['boxes'], colors):
                patch.set_facecolor(color)
            for flier, color in zip(bplot['fliers'], colors):
                flier.set_markerfacecolor(color)

            # Set plot title and labels
            plt.title(f'Box plot for {rouge_type} Across Bit Models')
            plt.xlabel("Quantized Model")
            plt.ylabel('Rouge Score')

            # Show the plot
            plt.show()


class BertMetric:
    def __init__(self) -> None:
        """ Instantiate BertMetric with Bert model.
        
        Params:
            None

        Returns:
            None
        """
        self.bert = load("bertscore")
        self.BERT_METRICS = ["precision", "recall", "f1"]
        self.bert_scores = {}  # Dictionary to store Bert scores for each dataframe
        for dataframe_name in ["df_q4", "df_q5", "df_q8"]:
            self.bert_scores[dataframe_name] = {
                metric: {"data": [], "statistics": {"mean": 0, "median": 0, "mode": 0, "stdev": 0}}
                for metric in self.BERT_METRICS
            }
        print("Bert Metric loaded successfully.")

    def getBertMetric(self, df_q4: pd.DataFrame, df_q5: pd.DataFrame, df_q8: pd.DataFrame) -> None:
        """ This function is used to compute Bert Score for each data point and generate the statistics for precision, recall, and F1-Score. 
        
        Params:
            df_q4: DataFrame generated by MyModel model as a result containing Generated Text and Reference Text for each datapoint by 4-bit Bloke LLM.
            df_q5: DataFrame generated by MyModel model as a result containing Generated Text and Reference Text for each datapoint by 5-bit Bloke LLM.
            df_q8: DataFrame generated by MyModel model as a result containing Generated Text and Reference Text for each datapoint by 8-bit Bloke LLM.

        Returns:
            None
        """
        dataframes = {"df_q4": df_q4, "df_q5": df_q5, "df_q8": df_q8}
        
        for dataframe_name, dataframe in dataframes.items():
            for index, row in dataframe.iterrows():
                computed_bert = self.bert.compute(predictions=[row['Generated Text']], references=[row['Reference Text']], lang="en")
                print("Computed Bert: ", computed_bert)
                print("\n\n")

                for metric in self.BERT_METRICS:
                    self.bert_scores[dataframe_name][metric]["data"].append(computed_bert[metric][0])
                    print(self.bert_scores)

            for metric in self.BERT_METRICS:
                v = self.bert_scores[dataframe_name][metric]
                v["statistics"]["mean"] = statistics.mean(v["data"])
                v["statistics"]["median"] = statistics.median(v["data"])
                v["statistics"]["mode"] = statistics.mode(v["data"])
                v["statistics"]["stdev"] = statistics.stdev(v["data"])
        
            print("***BERT SCORE***\n")
            for metric in self.BERT_METRICS:
                v = self.bert_scores[dataframe_name][metric]
                print(metric, v["statistics"])
        print(self.bert_scores)

        for metric in self.BERT_METRICS:
            fig = plt.figure(figsize=(5, 5))
            df_q4_data = self.bert_scores['df_q4'][metric]['data']
            df_q5_data = self.bert_scores['df_q5'][metric]['data']
            df_q8_data = self.bert_scores['df_q8'][metric]['data']
            boxprops = dict(facecolor = "none", edgecolor = 'black')
            medianprops = dict(color='black')
            flierprops = dict(marker = 'o', markerfacecolor = "#F55252", markersize = 8, linestyle = 'none')

            bplot = plt.boxplot([df_q4_data, df_q5_data, df_q8_data], labels=['4 bit', '5 bit', '8 bit'], patch_artist=True, boxprops=boxprops, medianprops=medianprops, flierprops=flierprops)

            colors = ['skyblue', 'lightgreen', 'yellow']  # Colors for 4 bit, 5 bit, 8 bit
            for patch, color in zip(bplot['boxes'], colors):
                patch.set_facecolor(color)
            for flier, color in zip(bplot['fliers'], colors):
                flier.set_markerfacecolor(color)

            # Set plot title and labels
            plt.title(f'Box plot for Bert {metric.capitalize()} Across Bit Models')
            plt.xlabel("Quantized Model")
            plt.ylabel(f'Bert {metric.capitalize()}')

            # Show the plot
            plt.show()
class RobertaMetric:
    def __init__(self) -> None:
        """ Instantiate RobertaMetric with Roberta Large V1 model.
        
        Params:
            None

        Returns:
            None
        """
        self.model = SentenceTransformer('sentence-transformers/all-roberta-large-v1')
        self.robertaStatistics = {"mean": 0, "median": 0, "mode": 0, "stdev": 0}
        self.ROBERTA_METRICS = ["Cosine Similarity"]
        self.roberta_scores = {}  # Dictionary to store Roberta scores for each dataframe
        for dataframe_name in ["df_q4", "df_q5", "df_q8"]:
            self.roberta_scores[dataframe_name] = {
                metric: {"data": [], "statistics": {"mean": 0, "median": 0, "mode": 0, "stdev": 0}}
                for metric in self.ROBERTA_METRICS
            }
        print("Roberta Model loaded successfully.")

    def __calculate_similarity(self, row: pd.Series) -> float:
        """ This function is used to compute cosine similarity for each row of a DataFrame containing generated and reference text.
        
        Params:
            row: A row of a dataframe containing generated and reference text.

        Returns:
            Float: A floating value indicating cosine similarity.
        """
        embeddings = self.model.encode([row['Reference Text'], row['Generated Text']])
        similarity_matrix = cosine_similarity([embeddings[0]], [embeddings[1]])
        return similarity_matrix[0][0]
    
    def getRobertaMetrics(self, df_q4: pd.DataFrame, df_q5: pd.DataFrame, df_q8: pd.DataFrame) -> None:
        """ This function is used to generate stats for Roberta Model using cosine similarity.
        
        Params:
            df_q4: DataFrame generated by MyModel model as a result containing Generated Text and Reference Text for each datapoint by 4-bit Bloke LLM.
            df_q5: DataFrame generated by MyModel model as a result containing Generated Text and Reference Text for each datapoint by 5-bit Bloke LLM.
            df_q8: DataFrame generated by MyModel model as a result containing Generated Text and Reference Text for each datapoint by 8-bit Bloke LLM.

        Returns:
            None
        """
        dataframes = {"df_q4": df_q4, "df_q5": df_q5, "df_q8": df_q8}
        
        for dataframe_name, dataframe in dataframes.items():
            for index, row in dataframe.iterrows():
                cosine_similarity_score = self.__calculate_similarity(row)
                self.roberta_scores[dataframe_name]["Cosine Similarity"]["data"].append(cosine_similarity_score)

        for metric in self.ROBERTA_METRICS:
            for dataframe_name in self.roberta_scores:
                v = self.roberta_scores[dataframe_name][metric]
                v["statistics"]["mean"] = statistics.mean(v["data"])
                v["statistics"]["median"] = statistics.median(v["data"])
                v["statistics"]["mode"] = statistics.mode(v["data"])
                v["statistics"]["stdev"] = statistics.stdev(v["data"])
        
        print("***ROBERTA SCORES***\n")
        for metric in self.ROBERTA_METRICS:
            print(f"Metric: {metric}")
            for dataframe_name in self.roberta_scores:
                v = self.roberta_scores[dataframe_name][metric]
                print(f"{dataframe_name}: {v['statistics']}")
        print("\n")

        fig = plt.figure(figsize=(5, 5))
        df_q4_data = self.roberta_scores['df_q4']["Cosine Similarity"]["data"]
        df_q5_data = self.roberta_scores['df_q5']["Cosine Similarity"]["data"]
        df_q8_data = self.roberta_scores['df_q8']["Cosine Similarity"]["data"]

        boxprops = dict(facecolor = "none", edgecolor = 'black')
        medianprops = dict(color='black')
        flierprops = dict(marker = 'o', markerfacecolor = "#F55252", markersize = 8, linestyle = 'none')

        bplot = plt.boxplot([df_q4_data, df_q5_data, df_q8_data], labels=['4 bit', '5 bit', '8 bit'], patch_artist=True, boxprops=boxprops, medianprops=medianprops, flierprops=flierprops)

        colors = ['skyblue', 'lightgreen', 'yellow']  # Colors for 4 bit, 5 bit, 8 bit
        for patch, color in zip(bplot['boxes'], colors):
            patch.set_facecolor(color)
        for flier, color in zip(bplot['fliers'], colors):
            flier.set_markerfacecolor(color)

        # Set plot title and labels
        plt.title('Roberta Metrics Across Bit Models')
        plt.xlabel("Quantized Model")
        plt.ylabel('Cosine Similarity')

        plt.show()
class PyTorchMetric:
    def __init__(self) -> None:
        nltk.download('punkt')
        print("PyTorch Model loaded successfully.")

    def __cosine_similarity_pytorch(self, text1: str, text2: str) -> float:
        """ This function is used to find the cosine similarity between two tensors using both the texts. 
        
        Params:
            text1: A string to compute cosine similarity.
            text2: A string to compute cosine similarity.

        Returns:
            float: Computed cosine similarity between two strings. 
        """
        # Preprocess the texts
        text1 = preprocess_text(text1)
        text2 = preprocess_text(text2)

        # Create word frequency dictionaries
        text1_counter = Counter(text1)
        text2_counter = Counter(text2)

        # Get unique words
        words = list(set(text1 + text2))

        # Create word vectors
        vector1 = [text1_counter[word] for word in words]
        vector2 = [text2_counter[word] for word in words]

        # Convert vectors to tensors
        text1_tensor = torch.tensor(vector1, dtype=torch.float)
        text2_tensor = torch.tensor(vector2, dtype=torch.float)

        # Calculate dot product
        dot_product = torch.dot(text1_tensor, text2_tensor)

        # Calculate norms
        norm1 = torch.norm(text1_tensor)
        norm2 = torch.norm(text2_tensor)

        # Calculate cosine similarity
        cosine_similarity = dot_product / (norm1 * norm2)

        return cosine_similarity.item()

    def getPyTorch(self, df_4bit: pd.DataFrame, df_5bit: pd.DataFrame, df_8bit: pd.DataFrame) -> None:
        df_q4_data = [self.__cosine_similarity_pytorch(row['Reference Text'], row['Generated Text']) for index, row in df_4bit.iterrows()]
        df_q5_data = [self.__cosine_similarity_pytorch(row['Reference Text'], row['Generated Text']) for index, row in df_5bit.iterrows()]
        df_q8_data = [self.__cosine_similarity_pytorch(row['Reference Text'], row['Generated Text']) for index, row in df_8bit.iterrows()]
        
        fig = plt.figure(figsize=(5, 5))
        boxprops = dict(facecolor = "none", edgecolor = 'black')
        medianprops = dict(color='black')
        flierprops = dict(marker = 'o', markerfacecolor = "#F55252", markersize = 8, linestyle = 'none')
        bplot = plt.boxplot([df_q4_data, df_q5_data, df_q8_data], labels=['4 bit', '5 bit', '8 bit'], patch_artist=True, boxprops=boxprops, medianprops=medianprops, flierprops=flierprops)
        colors = ['skyblue', 'lightgreen', 'yellow']  # Colors for 4 bit, 5 bit, 8 bit
       
        for patch, color in zip(bplot['boxes'], colors):
            patch.set_facecolor(color)
        for flier, color in zip(bplot['fliers'], colors):
            flier.set_markerfacecolor(color)

        plt.title('PyTorch Metric Across Bit Models')
        plt.ylabel('Cosine Similarity')
        plt.xlabel("Quantized Model")

        plt.show()

class WordEmbeddingsModel:    
    def __init__(self, word2VecModelName) -> None:
        """ Instantiate WordEmbedding for Glove, Word2Vec and FastText models based on model name.
        
        Params:
            word2VecModelName: A string value containing word-embedding model name to instantiate the model.

        Returns:
            None
        """
        self.wordEmbeddingsModelName = word2VecModelName
        nltk.download('punkt')
        self.wordEmbeddingsModel = {"mean": 0, "median": 0, "mode": 0, "stdev": 0}

        if word2VecModelName == "Word2Vec":
            self.file_path="../../../WordEmbeddings/GoogleNews-vectors-negative300.bin"
            self.model = KeyedVectors.load_word2vec_format(self.file_path, binary=True)
        
        elif word2VecModelName == "GLOVE":
            self.file_path = '../../../WordEmbeddings/glove.6B.300d.txt'
            glove_input_file = self.file_path

            # Path to word2vec format output file
            self.file_path = self.file_path + "glove.6B.300d.word2vec.txt"

            # save in word2vec format
            glove2word2vec(glove_input_file,self.file_path)
            self.model = KeyedVectors.load_word2vec_format(self.file_path, binary=False)

        elif word2VecModelName == "FASTTEXT":
            self.file_path = '../../../WordEmbeddings/wiki-news-300d-1M.vec'
            self.model = KeyedVectors.load_word2vec_format(self.file_path, binary=False)

        else:
            raise RuntimeError("Invalid word2vec model name.")
        print("***{}***".format(word2VecModelName))
    
    def getWordEmbeddings(self, df_4bit: pd.DataFrame, df_5bit: pd.DataFrame, df_8bit: pd.DataFrame):
        """ Generate cosine similarities for multiple data frames and plot a comparative box plot for each model.
        Params:
            df_4bit: DataFrame for 4-bit model.
            df_5bit: DataFrame for 5-bit model.
            df_8bit: DataFrame for 8-bit model.
        Returns:
            None
        """
        data = []
        labels = ['4 bit', '5 bit', '8 bit']
        dfs = [df_4bit, df_5bit, df_8bit]

        for df in dfs:
            similarities = []
            for _, row in df.iterrows():
                vector_1_array = []
                vector_2_array = []

                # Tokenize and preprocess text
                preprocess_text1 = preprocess_text(row['Generated Text'])
                preprocess_text2 = preprocess_text(row['Reference Text'])
                # Generate arrays to store word vectors
                for word in preprocess_text1:
                    try:
                        vector_1_array.append(self.model[word])
                    except KeyError:
                        # If the word is not in the vocabulary, you can skip it or use a default value
                        pass

                # Create word vectors for each word in 'Reference Text'
                for word in preprocess_text2:
                    try:
                        vector_2_array.append(self.model[word])
                    except KeyError:
                        # If the word is not in the vocabulary, you can skip it or use a default value
                        pass
                # Calculate column-wise averages for 'Generated Text' vectors
                vec_1_sums = np.mean(vector_1_array, axis=0)

                # Calculate column-wise averages for 'Reference Text' vectors
                vec_2_sums = np.mean(vector_2_array, axis=0)

                # Calculate cosine similarity
                similarity_matrix = cosine_similarity(vec_1_sums.reshape(1, -1), vec_2_sums.reshape(1, -1))

                # Get the similarity score between the two vectors
                cosine_similarity_score = similarity_matrix[0][0]
                similarities.append(cosine_similarity_score)
            data.append(similarities)
            print(similarities)


        # Plotting the results
        fig = plt.figure(figsize=(5, 5))
        boxprops = dict(facecolor = "none", edgecolor = 'black')
        medianprops = dict(color='black')
        flierprops = dict(marker = 'o', markerfacecolor = "#F55252", markersize = 8, linestyle = 'none')
        bplot = plt.boxplot(data, labels=['4 bit', '5 bit', '8 bit'], patch_artist=True, boxprops=boxprops, medianprops=medianprops, flierprops=flierprops)
        colors = ['skyblue', 'lightgreen', 'yellow']  # Colors for 4 bit, 5 bit, 8 bit
       
        for patch, color in zip(bplot['boxes'], colors):
            patch.set_facecolor(color)
        for flier, color in zip(bplot['fliers'], colors):
            flier.set_markerfacecolor(color)

        plt.title(f'{self.wordEmbeddingsModelName} Cosine Similarities Across Bit Models')
        plt.xlabel("Quantized Model")
        plt.ylabel('Cosine Similarity')
        plt.show()

class DataVisualizer:
    def check_for_zero_lengths(self, data_frames_by_bit, labels):
        """Checks for zero-length generated texts and prints details."""
        zero_length_info = {}
        for label, dfs in zip(labels, data_frames_by_bit):
            zero_length_info[label] = []
            for i, df in enumerate(dfs):
                zero_count = (df['Generated Text Length'] == 0).sum()
                if zero_count > 0:
                    zero_length_info[label].append((i+1, zero_count))
        return zero_length_info
    
    def plot_combined_prompts_across_bits(self, data_sets, labels):
        # Combine all prompt data for each bit configuration into one box per bit
        combined_data = [pd.concat([df['Generated Text Length'] for df in bit_data], ignore_index=True) for bit_data in data_sets]

        # Create a boxplot
        fig, ax = plt.subplots(figsize=(10, 10))
        boxprops = dict(facecolor = "none", edgecolor = 'black')
        medianprops = dict(color='black')
        flierprops = dict(marker = 'o', markerfacecolor = "#F55252", markersize = 8, linestyle = 'none')

        bplot = ax.boxplot(combined_data, patch_artist=True,
                       boxprops=boxprops, medianprops=medianprops, flierprops=flierprops)
        colors = ['skyblue', 'lightgreen', 'yellow', 'orange']  # Colors for 4 bit, 5 bit, 8 bit, base model

        for patch, color in zip(bplot['boxes'], colors):
            patch.set_facecolor(color)
        for flier, color in zip(bplot['fliers'], colors):
            flier.set_markerfacecolor(color)

        # Setting custom y-axis ticks
        ax.yaxis.set_major_locator(MultipleLocator(1000))  # Major ticks every 1000 words
        ax.yaxis.set_minor_locator(AutoMinorLocator(4))    # Four minor ticks between major ticks
        ax.yaxis.set_major_formatter(FormatStrFormatter('%d words'))  # Format text to include 'words'

        ax.set_title('Combined Distribution of Generated Text Length Across All Prompts for Each Bit Configuration vs Base Model')
        ax.set_ylabel('Generated Text Length (Words)')
        ax.set_xlabel('LLaMA-2 Model Variants')
        ax.set_xticks(range(1, len(labels) + 1))
        ax.set_xticklabels(labels)

        plt.show()


class WordEmbeddingsModel2:    
    def __init__(self, word2VecModelName) -> None:
        """ Instantiate WordEmbedding for Glove, Word2Vec and FastText models based on model name.
        
        Params:
            word2VecModelName: A string value containing word-embedding model name to instantiate the model.

        Returns:
            None
        """
        self.wordEmbeddingsModelName = word2VecModelName
        nltk.download('punkt')
        self.wordEmbeddingsModel = {"mean": 0, "median": 0, "mode": 0, "stdev": 0}

        if word2VecModelName == "Word2Vec":
            self.file_path="../../../WordEmbeddings/GoogleNews-vectors-negative300.bin"
            self.model = KeyedVectors.load_word2vec_format(self.file_path, binary=True)
        
        elif word2VecModelName == "GLOVE":
            self.file_path = '../../../WordEmbeddings/glove.6B.300d.txt'
            glove_input_file = self.file_path

            # Path to word2vec format output file
            self.file_path = self.file_path + "glove.6B.300d.word2vec.txt"

            # save in word2vec format
            glove2word2vec(glove_input_file,self.file_path)
            self.model = KeyedVectors.load_word2vec_format(self.file_path, binary=False)

        else:
            raise RuntimeError("Invalid word2vec model name.")
        print("***{}***".format(word2VecModelName))
    
    def getWordEmbeddings(self, df_4bit: pd.DataFrame, df_5bit: pd.DataFrame, df_8bit: pd.DataFrame, df_base:pd.DataFrame):
        """ Generate cosine similarities for multiple data frames and plot a comparative box plot for each model.
        Params:
            df_4bit: DataFrame for 4-bit model.
            df_5bit: DataFrame for 5-bit model.
            df_8bit: DataFrame for 8-bit model.
        Returns:
            None
        """
        data = []
        labels = ['4 bit', '5 bit', '8 bit', 'Base Model']
        dfs = [df_4bit, df_5bit, df_8bit, df_base]

        for df in dfs:
            similarities = []
            for _, row in df.iterrows():
                vector_1_array = []
                vector_2_array = []

                # Tokenize and preprocess text
                preprocess_text1 = preprocess_text(row['Generated Text'])
                preprocess_text2 = preprocess_text(row['Reference Text'])
                # Generate arrays to store word vectors
                for word in preprocess_text1:
                    try:
                        vector_1_array.append(self.model[word])
                    except KeyError:
                        # If the word is not in the vocabulary, you can skip it or use a default value
                        pass

                # Create word vectors for each word in 'Reference Text'
                for word in preprocess_text2:
                    try:
                        vector_2_array.append(self.model[word])
                    except KeyError:
                        # If the word is not in the vocabulary, you can skip it or use a default value
                        pass
                # Calculate column-wise averages for 'Generated Text' vectors
                vec_1_sums = np.mean(vector_1_array, axis=0)

                # Calculate column-wise averages for 'Reference Text' vectors
                vec_2_sums = np.mean(vector_2_array, axis=0)

                # Calculate cosine similarity
                similarity_matrix = cosine_similarity(vec_1_sums.reshape(1, -1), vec_2_sums.reshape(1, -1))

                # Get the similarity score between the two vectors
                cosine_similarity_score = similarity_matrix[0][0]
                similarities.append(cosine_similarity_score)
            data.append(similarities)
            print(similarities)


        # Plotting the results
        fig = plt.figure(figsize=(5, 5))
        boxprops = dict(facecolor = "none", edgecolor = 'black')
        medianprops = dict(color='black')
        flierprops = dict(marker = 'o', markerfacecolor = "#F55252", markersize = 8, linestyle = 'none')
        bplot = plt.boxplot(data, labels=['4 bit', '5 bit', '8 bit', 'Base Model'], patch_artist=True, boxprops=boxprops, medianprops=medianprops, flierprops=flierprops)
        colors = ['skyblue', 'lightgreen', 'yellow', 'orange']  # Colors for 4 bit, 5 bit, 8 bit
       
        for patch, color in zip(bplot['boxes'], colors):
            patch.set_facecolor(color)
        for flier, color in zip(bplot['fliers'], colors):
            flier.set_markerfacecolor(color)

        plt.title(f'{self.wordEmbeddingsModelName} Cosine Similarities Across Quantized and Base LLaMA-2 Models')
        plt.xlabel("LLaMA-2 Model Variants")
        plt.ylabel('Cosine Similarity')
        plt.show()
   
class ComparativeTextMetrics:
    def __init__(self):
        """ Initializes the Rouge evaluation metric. """
        self.rouge = load('rouge')
        self.bert = load('bertscore') 

    def extract_rouge_lsum(self, df):
        rouge_lsum_scores = []
        for index, row in df.iterrows():
            try:
                computed_rouge = self.rouge.compute(predictions=[row['Generated Text']], references=[row['Reference Text']], rouge_types=["rougeLsum"])
                print("Computed Rouge: ", computed_rouge)
                print("\n\n")
                # Directly access the 'rougeLsum' score which is a float
                rouge_lsum_scores.append(computed_rouge['rougeLsum'])  # Directly append the float value
            except Exception as e:
                print(f"Failed to compute ROUGE-Lsum score for index {index}: {e}")

        return rouge_lsum_scores

    def compute_bert_precision(self, dfs):
        """Compute BERT precision for a list of DataFrames."""
        precisions = []
        for _, row in dfs.iterrows():
            score = self.bert.compute(predictions=[row['Generated Text']], references=[row['Reference Text']], lang="en")
            precisions.append(score['precision'][0])  # Extract the first (and only) precision score
        return precisions

    def generate_boxplot_for_bits(self, bit_data,labels, title, x_label, y_label):
        """ Generates a box plot for the different bit configurations.

        Params:
            bit_data (list of list): A list containing ROUGE-Lsum scores for each bit configuration.
            labels (list): A list of labels for each bit configuration.
        """
        plt.figure(figsize=(10, 6))
        boxprops = dict(facecolor = "none", edgecolor = 'black')
        medianprops = dict(color='black')
        flierprops = dict(marker = 'o', markerfacecolor = "#F55252", markersize = 8, linestyle = 'none')

        bplot = plt.boxplot(bit_data, labels=labels, patch_artist=True,
                    boxprops=boxprops, medianprops=medianprops, flierprops=flierprops)
        colors = ['skyblue', 'lightgreen', 'yellow', 'orange']  # Colors for 4 bit, 5 bit, 8 bit
       
        for patch, color in zip(bplot['boxes'], colors):
            patch.set_facecolor(color)
        for flier, color in zip(bplot['fliers'], colors):
            flier.set_markerfacecolor(color)
        
        bplot = plt.boxplot(bit_data, labels=labels, patch_artist=True,
                    boxprops=boxprops, medianprops=medianprops, flierprops=flierprops)
        plt.title(title)
        plt.xlabel(x_label)
        plt.ylabel(y_label)
        plt.show()

    def analyze(self, df_4bit, df_5bit, df_8bit, df_base):
        rouge_lsum_4bit = self.extract_rouge_lsum(df_4bit)
        rouge_lsum_5bit = self.extract_rouge_lsum(df_5bit)
        rouge_lsum_8bit = self.extract_rouge_lsum(df_8bit)
        rouge_lsum_base = self.extract_rouge_lsum(df_base)
        print("4-bit")
        print(rouge_lsum_4bit)
        print("5-bit")
        print(rouge_lsum_5bit)
        print("8-bit")
        print(rouge_lsum_8bit)
        print("Base model")
        print(rouge_lsum_base)
        self.generate_boxplot_for_bits([rouge_lsum_4bit, rouge_lsum_5bit, rouge_lsum_8bit, rouge_lsum_base], ['4-bit', '5-bit', '8-bit', 'Base Model'],title =  "ROUGE-Lsum Score Variability Across Quantized and Base LLaMA-2 Models", x_label = "LLaMA-2 Model Variants", y_label = "ROUGE-Lsum Scores")
        bert_precisions_4bit = self.compute_bert_precision(df_4bit)
        bert_precisions_5bit = self.compute_bert_precision(df_5bit)
        bert_precisions_8bit = self.compute_bert_precision(df_8bit)
        bert_precisions_base = self.compute_bert_precision(df_base)
        print("4-bit")
        print(bert_precisions_4bit)
        print("5-bit")
        print(bert_precisions_5bit)
        print("8-bit")
        print(bert_precisions_8bit)
        self.generate_boxplot_for_bits([bert_precisions_4bit, bert_precisions_5bit, bert_precisions_8bit, bert_precisions_base], ['4-bit', '5-bit', '8-bit', 'Base Model'], title =  "Bert-Precision Score Variability Across Quantized and Base LLaMA-2 Models",x_label = "LLaMA-2 Model Variants", y_label="Bert-Precision Scores")


class Metrics:
    def getAllMetrics(self, df: pd.DataFrame) -> None:
        """ This function is used to generate mertics for a dataframe containing reference and generated text using 
            Rogue, Bert, Roberta, PyTorch, Word2Vec, Glove and FastText.
        
        Params:
            df: A DataFrame containing reference and generated text of each datapoint.

        Returns:
            None
        """
        rougeMetric = RougeMetric()
        rougeMetric.getRougeMetric(df)
        bertMetric = BertMetric()
        bertMetric.getBertMetric(df)
        robertaMetric = RobertaMetric()
        robertaMetric.getRobertaMetrics(df)
        pyTorchMetric = PyTorchMetric()
        pyTorchMetric.getPyTorch(df)

        WordEmbeddingModels = ["Word2Vec", "GLOVE", "FASTTEXT"]
        for wordEmbeddingModelName in WordEmbeddingModels:
            wordEmbeddingModel = WordEmbeddingsModel(wordEmbeddingModelName)
            wordEmbeddingModel.getWordEmbeddings(df)

class CombinedMetrics:
    def getAllMetrics(self, df_4bit: pd.DataFrame, df_5bit: pd.DataFrame,df_8bit: pd.DataFrame,df_base: pd.DataFrame) -> None:
        comparativerougeLsum = ComparativeTextMetrics()
        comparativerougeLsum.analyze(df_4bit, df_5bit, df_8bit, df_base) 
        WordEmbeddingModels = ["Word2Vec", "GLOVE"]
        for wordEmbeddingModelName in WordEmbeddingModels:
            wordEmbeddingModel = WordEmbeddingsModel2(wordEmbeddingModelName)
            wordEmbeddingModel.getWordEmbeddings(df_4bit, df_5bit, df_8bit, df_base)

